{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LEfLLMOGaJdX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import sample\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLv9_dscajCf",
        "outputId": "1b1e6f9e-82e9-47df-84fd-ef90ea12e472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d-VZWNa9aUg7"
      },
      "outputs": [],
      "source": [
        "df= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/trainwithzerostopredict.csv')\n",
        "topredict= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/topredict.csv')\n",
        "df_withoutzero= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/trainwithoutzeros.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JDD1NricJu8"
      },
      "source": [
        "***df has all the topredict values entered as 0 for the Book-Rating column.***</br>\n",
        "***topredict has all the values that we want to predict.***</br>\n",
        "***df_withoutzero has all the topredict all the values including the values in the test dataset.***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X02QrZNcDk1",
        "outputId": "58edc408-1a6f-4324-81f7-0549453d2813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77805"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['User-ID'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3-rphUEdM4C",
        "outputId": "e3fdcc43-0bee-4952-a3dc-2b72b2955454"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19935"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topredict['User-ID'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VaKrg6SdpoK"
      },
      "source": [
        "##**500 users that rate the most**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ukwD4It0dPN0"
      },
      "outputs": [],
      "source": [
        "df_num_rating= df.groupby('User-ID').agg(Number_of_ratings=('Book-Rating','count')).reset_index()\n",
        "# Num ratings count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cG88rUdId80l",
        "outputId": "6eaa8fa8-72b7-4f89-f14a-52512d326690"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1ca1e545-f959-41f5-8934-c967c3d40a93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User-ID</th>\n",
              "      <th>Number_of_ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3160</th>\n",
              "      <td>11676</td>\n",
              "      <td>8524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27626</th>\n",
              "      <td>98391</td>\n",
              "      <td>5802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43027</th>\n",
              "      <td>153662</td>\n",
              "      <td>1969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52924</th>\n",
              "      <td>189835</td>\n",
              "      <td>1906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6510</th>\n",
              "      <td>23902</td>\n",
              "      <td>1395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23601</th>\n",
              "      <td>84129</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46266</th>\n",
              "      <td>165812</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9606</th>\n",
              "      <td>34231</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46268</th>\n",
              "      <td>165826</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11753</th>\n",
              "      <td>41658</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77805 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ca1e545-f959-41f5-8934-c967c3d40a93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ca1e545-f959-41f5-8934-c967c3d40a93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ca1e545-f959-41f5-8934-c967c3d40a93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       User-ID  Number_of_ratings\n",
              "3160     11676               8524\n",
              "27626    98391               5802\n",
              "43027   153662               1969\n",
              "52924   189835               1906\n",
              "6510     23902               1395\n",
              "...        ...                ...\n",
              "23601    84129                  1\n",
              "46266   165812                  1\n",
              "9606     34231                  1\n",
              "46268   165826                  1\n",
              "11753    41658                  1\n",
              "\n",
              "[77805 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_num_rating.sort_values(by=['Number_of_ratings'], ascending=False, inplace=True)\n",
        "df_num_rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aokbHPwXeKaV"
      },
      "outputs": [],
      "source": [
        "top_users= df_num_rating['User-ID'][:500]\n",
        "# top 500 users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jgioy1Qevic"
      },
      "source": [
        "##**To Predict User List and Batch Designation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5vN4V94erw0",
        "outputId": "a60e005a-5065-410e-eaf9-7e4931849b69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([    17,     56,    114, ..., 278844, 278851, 278854])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "topredict_users= topredict['User-ID'].unique()\n",
        "topredict_users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFpz8A1SfKkv",
        "outputId": "43bd3faa-dc7a-4665-c2c3-2e478a39b243"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19935"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(topredict_users)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59pNpzeP-a8C"
      },
      "source": [
        "**We divide the test into 20 folds because of memory limitations. We will predict the test values by loading in batches**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xh4Ko2NIfP0J"
      },
      "outputs": [],
      "source": [
        "dict_batch= {}\n",
        "for i in range(0,len(topredict_users),1000):\n",
        "  dict_batch['fold_{}'.format(i//1000)]= topredict_users[i:i+1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eaSqpvXZ_CmJ"
      },
      "outputs": [],
      "source": [
        "# this is the matrix factorization function from the MF notebook. \n",
        "def MF(M,k,max_it,lambd,mu):\n",
        "    n=M.size()[0]\n",
        "    m= M.size()[1]\n",
        "    nonzero=len(M.nonzero())\n",
        "    index= M.nonzero().split(1, dim=1)\n",
        "    #param=torch.rand(n*k+k*m,dtype=float,requires_grad=True)\n",
        "    param1=torch.rand((n,k),dtype=torch.float,requires_grad=True)\n",
        "    param2=torch.rand((k,m),dtype=torch.float,requires_grad=True)\n",
        "\n",
        "    opt1= torch.optim.Adam([param1],lr=0.1)\n",
        "    opt2= torch.optim.Adam([param2],lr=0.1)\n",
        "    \n",
        "    #scheduler1= ReduceLROnPlateau(opt1, 'min') \n",
        "    #scheduler2 = ReduceLROnPlateau(opt2, 'min')\n",
        "    \n",
        "\n",
        "    #def get_loss(params,params_hat):\n",
        "        #return torch.sum(torch.square(params- params_hat))\n",
        "\n",
        "    def run_iterations(max_it):\n",
        "        loss_record=[]\n",
        "        converged=False\n",
        "        for it in tqdm(range(max_it)):\n",
        "            if it%2==0:\n",
        "                opt1.zero_grad(set_to_none=True)\n",
        "                #torch.matmul(param[:n*k].reshape(n,k), pam[n*k:].reshape(k,m))\n",
        "                loss=torch.sum(torch.square(torch.matmul(param1, param2)[index]- M[index])) + lambd*torch.sum(torch.square(param1))+mu*torch.sum(torch.square(param2))\n",
        "                loss_record.append(loss.item())\n",
        "                loss.backward()\n",
        "                opt1.step()\n",
        "                #scheduler1.step(loss)\n",
        "            else:\n",
        "                opt2.zero_grad(set_to_none=True)\n",
        "                #torch.matmul(param[:n*k].reshape(n,k), pam[n*k:].reshape(k,m))\n",
        "                loss=torch.sum(torch.square(torch.matmul(param1, param2)[index]- M[index])) + lambd*torch.sum(torch.square(param1))+mu*torch.sum(torch.square(param2))\n",
        "                loss_record.append(loss.item())\n",
        "                loss.backward()\n",
        "                opt2.step()\n",
        "                #scheduler2.step(loss)\n",
        "        display(loss_record)\n",
        "        return torch.matmul(param1,param2)\n",
        "    return run_iterations(max_it)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMUZRHqY_gks"
      },
      "source": [
        "**The following loop loads the ith batch of the train dataset and constructs a matrix using the ith batch and the subset of the train dataset containing the 500 top users. Then it computes the matrix factorization prediction on the ith batch. It calculates the MSE for each batch in each iteration.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PAivGJnbgKNB",
        "outputId": "6b2f35d6-aabe-4ed2-e97c-da2c9135d1fd"
      },
      "outputs": [],
      "source": [
        "mse_batch=[] # this will collect the batch MSE\n",
        "indices_batch=[] # this will collect the indices of the test dataset in each batch\n",
        "for i in range(len(dict_batch)): #length of dict_batch is 20 because we have 20 folds\n",
        "  df_batch= topredict[topredict['User-ID'].isin(dict_batch['fold_{}'.format(i)])].reset_index(drop=True)\n",
        "  df_matrix= df[df['User-ID'].isin(list(dict_batch['fold_{}'.format(i)])+list(top_users))].reset_index(drop=True) #combines data from 500 top users and the test batch\n",
        "  mat= df_matrix.pivot(index='User-ID',columns='ISBN',values='Book-Rating') .fillna(0) # matrix using pivot\n",
        "  matrix= torch.tensor(mat.values)/10 #converts to tensor and scales the values by 1/10\n",
        "  dict_user= dict(zip(sorted(set(df_matrix['User-ID'])),range(len(sorted(set(df_matrix['User-ID']))))))\n",
        "  dict_book= dict(zip(sorted(set(df_matrix['ISBN'])),range(len(sorted(set(df_matrix['ISBN']))))))\n",
        "  index1=[] #this will collect the row index\n",
        "  index2=[] #this will collect the column index\n",
        "  for j in range(len(df_batch)):\n",
        "    index1.append([dict_user[df_batch['User-ID'][j]]])\n",
        "    index2.append([dict_book[df_batch['ISBN'][j]]])\n",
        "  indices_topred = (torch.tensor(index1),torch.tensor(index1)) #this contains the indices from the matrix whose values we want to predict\n",
        "  # this is a bit peculiar but torch tensors work this way\n",
        "  df_actual= df_withoutzero[df_withoutzero['User-ID'].isin(list(dict_batch['fold_{}'.format(i)])+list(top_users))]\n",
        "  # df_actual is the matrix with the ratings of the test dataset included\n",
        "  # we need this to calculate MSE\n",
        "  actual_matrix= df_actual.pivot(index='User-ID',columns='ISBN',values='Book-Rating') .fillna(0)\n",
        "  actual_matrix= torch.tensor(actual_matrix.values)/10 # convert to tensor and scale like above\n",
        "\n",
        "  mse_batch.append(100*torch.sum(torch.square(MF(matrix,10,1500,0.1,0.1)[indices_topred]- actual_matrix[indices_topred])))\n",
        "  # we multiply by 10^2 because we scaled by 1/10 and squared\n",
        "  # the values 25,0.1,0.1 come from the MF validation notebook where we performed validation for parameter tuning \n",
        "  indices_batch.append(len(indices_topred[0]))\n",
        "  display(mse_batch[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4haqL6tGQtfj"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/mse_batch\", \"wb\") as fp:   #Pickling\n",
        "  pickle.dump(mse_batch, fp)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/indices_num_batch\", \"wb\") as fp:   #Pickling\n",
        "  pickle.dump(indices_batch, fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Xd6GOpIJO_ef"
      },
      "outputs": [],
      "source": [
        "mse= sum(mse_batch)/sum(indices_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wevp9NiGWTVL",
        "outputId": "f5050177-69e6-4e90-9ec6-615338b9e34f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7.8160, dtype=torch.float64, grad_fn=<DivBackward0>)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzWGnPm0DtCm",
        "outputId": "778b8cb9-7898-431a-ad90-d01af3eeeaa6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(2.7957, dtype=torch.float64)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rmse= np.sqrt(mse.detach())\n",
        "rmse"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
